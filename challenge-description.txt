Below is the Data Engineer coding challenge we send out to all candidates.  Please work to complete the challenge in Scala.  It will be reviewed by Sr. Engineers on the team that have also completed this same challenge.   As a suggestion, itâ€™s always best to triple check your response so it meets the requirements.  The candidates that typically fail are those that do not provide comments, test cases, a deployable solution or good documentation.  We understand you have a full-time job, but we also try and mimic an agile production environment by adding a reasonable deadline.  We ask candidates to send responses back in 7 days from receipt to keep the interview process moving forward.  It is not a hard requirement, but helps drive the interview process.   If you need extra time, that is ok, just let me know.  Please send back as a zip file or repo (google; github (public); etc).  We are having issues with large files over 25MB.  

 

If anything is unclear please make reasonable assumptions, document the assumptions and write the code with those assumptions in mind. Please write your program as if it were for production use, including whatever comments, test cases and documentation you think are necessary. The code must be stable, maintainable and mostly bug free. Please include something we can use to demonstrate that your answer is correct -- for example a test / unit test program, documentation or whatever you think will help us. In our production environment, we really care about things like unit testing, documentation, and deployability so showcasing your comfort with building quality code in an environment of this sort is paramount.  Think about things like test coverage and the fact that the people reviewing your project really want to see you successful, but need to be able to deploy and run your project easily in a clean environment.  Code as much as you can. If you cannot complete parts of the challenge at least show some design/code flow for the parts you could not complete.

The Challenge: Write a program in Scala that downloads the dataset at https://ditotw.space/NASA_access_log_Jul95.gz (let me know if you have any issues downloading it) and use Apache Spark to determine the top-n most frequent visitors and urls for each day of the trace.  Package the application in a docker container.
